---
title: "Problem Set 2 Adv-ERM"
author: "Carlos Gonzalez"
date: '2022-11-14'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#tinytex::install_tinytex() For knitting
```

# Problem Set 2a

```{r, results='hide', message=FALSE}
# Libraries
library(tidyverse)
library(readxl)
library(Rfast)
```


## Question 1

I believe that the use of mapply() is more standard as it returns back the simplified version of the multi-dimensional array that sapply() produces. Moreover, the inputs in mapply() take a more intuitive form than the ones in sapply().

```{r}
# Create function
easy = function(a,b){
  b*sqrt(a)
}

# Loop over using mapply vectorization
easy_results = mapply(easy,a = runif(100,2,4), b=2)

head(easy_results)
```

## Question 2

### Part a), b) and c)

```{r}
# Set seed
set.seed(1234)

# Generate logistic error terms
u_i = function(N){
  rlogis(N, location = 0, scale = 1)
}

# Generate y function
gen_y = function(N, theta_i){
  rnorm(N, mean = theta_i, 1)
}

# Wrapping function
wrap_function = function(N, theta){
  u_i = u_i(N)
  theta_i = theta + u_i
  y = gen_y(N, theta_i)
}

# Generate data using wrapping function
y = wrap_function(N = 1000, theta = 1)

# Plot
head(y)
plot(density(y))

```

### Part d), e), f) and g)

Although the density (likelihood function) of the DGP in this exercise is not high-dimensional, and potentially amenable to different kinds of numerical optimization, we have decided to produce MSL like estimators. The idea is to replace the integral over the nuisance parameter u for an average of uniformly drawn u terms using a guess of our parameter of interest (theta). We repeat this process for every observation y in the data and maximize the likelihood of the "guess parameter".

```{r}
# Create a function for identifying the contribution of a single observation
# to total log-likelihood

ind_l = function(y, theta_guess, u_i){
log(mean((1/sqrt(2*pi))*exp(-0.5*(y - theta_guess - u_i)^2)))
}

# where u_i is a N vector of error terms

# Simulate large N of errors

simulated_u = u_i(10000)

# Iterate this process for each y and fixed theta
# Compute total log-likelihood
# We give the function extra flexibility in terms of arguments
# for later steps in the exercises

loglik_MSL = function(theta, y, u_i){
  -mean(sapply(X = y, FUN = ind_l,
               theta_guess = theta, u_i = u_i))
}

# Optimization
results = optim(par = 0.1, loglik_MSL,
                method = "BFGS", y = y, u_i = simulated_u)
results$par
results$value
```

Our MSL estimator seems to work as it has returned a ML estimate very similar to the real DG parameter theta = 1.

### Part h) and i)

Our function works fine with different theta. In particular, for theta = 2.5, our MSL is 2.46 for 10,000 error draws. Bad news come from the fact that we don't get any closer to real theta by increasing the number of draws, nor does our LL value. The inclusion of more iid errors gets us very little in terms of improved likelihood. This is the main reason which explained the development of MCMC like simulations.

```{r}

# Changing theta
y_new = wrap_function(1000, 2.5)

# Optimize
draws_10000 = optim(par = 0.1, loglik_MSL,
                    method = "BFGS", y = y_new,
                    u_i = simulated_u)

# Changing number of error draws
new_u = u_i(20000)
draws_20000 = optim(par = 0.1, loglik_MSL,
                    method = "BFGS", y = y_new,
                    u_i = new_u)

# Value comparison
tibble("Number of draws" = c(10000, 20000), 
  "MLS" = c(draws_10000$par, draws_20000$par),
  "LL value" = c(draws_10000$value, draws_20000$value))

```

### Part j

Although actual parameter estimation will vary depending on the particular realization of the errors in each draw, usually we expect poor MSL estimates when errors are re-drawn. This is because our optimization method cannot distinguish if improvement in likelihood is due to improvement in change of parameters (theta) or due to varying error terms.

```{r}
# We use our original y dataset

# Create new optimization function

indiv_MSL_new = function(theta, y){
    redrawn_u = u_i(10000)
    ind_l(y = y, theta_guess = theta,
          u_i = redrawn_u)
}

loglik_MSL_new = function(theta, y){
 -mean(sapply(X = y, FUN = indiv_MSL_new,
         theta = theta))
}

# Observe that because errors are redrawn in each iteration,
# we do not have to include them as a parameter
redrawn_errors = optim(par = 0.1, loglik_MSL_new,
                      method = "BFGS", y = y)


tibble("Redraw errors" = c("No", "Yes"), 
  "MLS" = c(results$par, redrawn_errors$par),
  "LL value" = c(results$value, redrawn_errors$value))
```

# Problem Set 2b

## Question 1

This might be a problem because multinomial logit assumes that multinomial probabilities (the probability of voting each of the parties) depend only on (observable) party characteristics (x_j) plus some error term. However, in reality, we may expect that, even conditioned on covariates, transition probabilities (as defined by the probability of voting a different party conditioned on your party of choice not being available anymore) are not random. In particular, we may rightfully believe that your previous choice plays a role in your choice of counterfactual party.

Multinomial probit allows you to model this cross-dependent probabilities.

## Question 2

### Part a) and b)

```{r, warning=FALSE}
set.seed(1234)

# Parameters

N = 1000 #Number of individuals
J = 4 #Number of parties
tau = c(0.86, 0.16, 0.48, 0.92)
beta = -0.25

# Create generating var-covar matrix function

gen_sigma = function(rho, sigma_2){
  var_matrix = matrix(0, J, J)
  diag(var_matrix) = sigma_2
  var_matrix[2,1] = rho
  var_matrix[1,2] = rho
  var_matrix[3,4] = rho
  var_matrix[4,3] = rho
  var_matrix
}

# Generate benchmark sigma
var_covar = gen_sigma(0, 1)

# Generate data function as a function of a cholesky factor
gen_voting = function(L){

  # Simulate errors using Rfast
  e_ij = rmvnorm(N, mu = c(0,0,0,0), sigma = L*var_covar)
  
  voting_data = beta*tau + e_ij |> as_tibble()
  colnames(voting_data) = c("WWR", "WAWR", "WWL", "WAWL")
  
  # Recover selection and pivot_long
  voting_data = voting_data |>
                mutate(choice = colnames(voting_data)[apply(voting_data,1,which.max)],
                       id = 1:N) |>
                pivot_longer(starts_with('W'),
                             names_to = 'party', values_to = 'u_ij') |>
                mutate(d_ij = ifelse(party == choice, 1, 0))
  voting_data

}

# Generate (benchmark data) [2b]
voting_data_bench = gen_voting(1)
head(voting_data_bench)
```

### Part c)

```{r}
# Identify cholesky factor of matrix with rho = 0.9, sigma = 1
cholesky_matrix = gen_sigma(0.9, 1)
chol_factor = chol(cholesky_matrix)

# Generate new data
voting_data_new = gen_voting(chol_factor)
```

## Exercise 3

### Part a)

```{r}
set.seed(1234)

# Read data and some initial adjustments
real_voting = read_xlsx("../data/political_vote_choice.xlsx") |> as_tibble() |>
              pivot_longer(starts_with('tau_'),
                           names_to = 'party', values_to = 't_ij') |>
              mutate(party = as.numeric(gsub("tau_", "", party)),
                     d_ij = ifelse(party == vote, 1, 0))

# Share of voters
real_voting |> group_by(vote) |>
               summarise("Shares %" = 100*n()/nrow(real_voting))

# head(real_voting)

```

### Part b) and c)

```{r}
# Simulate fixed errors
R = 1000
J = 4

errors = rmvnorm(N, mu = rep(0,J), sigma = var_covar)

# Log-Likelihood function

ll_multi_probit = function(theta){
  
  #Recover parameters from input
  beta = theta[1]
  sigma_2 = theta[2]
  rho = theta[3]
  
  # Find associated chol
  cholesky_matrix = gen_sigma(rho, sigma_2)
  chol_factor = chol(cholesky_matrix)
    
  # Create function to apply() over errors
  single_error = function(errors){
      
    # Update errors
    errors_update = chol_factor%*% errors |> as.vector()
      
    # Gen updated utility using round r errors for all i
    data_base = real_voting |> select(id, party, t_ij) |>
                               mutate(u_ij = beta*t_ij + errors_update)
    
    # Identify maximum u_ij and the associated party
    max_ident = data_base |> select(id, u_ij) |> group_by(id) |>
                             summarise("max" = max(u_ij))
    data_base |> left_join(max_ident, by = "id") |>
                 filter(max == u_ij) |> arrange(id) |> select(party)
    }
    
    votes = apply(errors, 1, FUN = single_error) %>%
            do.call(cbind, .)
  
  # Compute probabilities
  probs = matrix(NA, nrow = nrow(votes), ncol = 4)
  for (j in 1:4){
     probs[,j] = rowSums(votes==j) / ncol(votes)
  }
  
  # Compute log density
  probs = probs |> as_tibble()
  colnames(probs) = c("p1", "p2", "p3", "p4")
  probs$id = seq(1:nrow(probs))
  probs = probs |> pivot_longer(starts_with("p"), names_to = "party",
                                values_to = "prob") |>
                  mutate(party = as.numeric(gsub("p", "", party)))
  
  final_base = real_voting |> select(id, party, d_ij) |>
               left_join(probs, by = c("id", "party"))
  
  -sum(final_base$d_ij*log(final_base$prob))

}

start_params = c(0,1,0.5)
ll_multi_probit(start_params)

```
### Part d)

Do NOT run for time considerations

```{r, eval = FALSE}
results_voting = optim(start_params,
                       ll_multi_probit,
                       method = "BGFS"
                       hessian = TRUE)
```

### Part e) and f)

Given that I have not run my optimization function for time considerations, I will take as true the following theta = (1, 1, 0.8). The intuition of the code below is to recover "true" u_ij based on recovered parameters and then select as conterfactual vote the party with the highest voting probability, conditional on that party not being the fourth party.

```{r}
# Recovered parameters (i.e. population parameters)
sigma_2_optim = 1
beta_optim = 1
rho_optim = 0.8

# Generate recovered Sigma
sigma_optim = gen_sigma(rho_optim, sigma_2_optim)

# Generate "true" errors
errors_optim = rmvnorm(10000, rep(0,4), sigma = sigma_optim)

# Generate "true" u_ij
u_ij_optim = beta_optim*tau + errors_optim

# Parties share if party collapse

# Create second_max function
second_max = function(u){
  match(sort(u,partial=2)[2],u)
}

simulation_base = u_ij_optim |> as_tibble()
colnames(simulation_base) = c("party_1","party_2","party_3","party_4")
simulation_base = simulation_base |> # round(digits = 3) |>
                  mutate(vote =                           
                         colnames(simulation_base)[apply(
                                  simulation_base,1,which.max)],
                         second_vote =
                         colnames(simulation_base)[apply(
                                  simulation_base,1,second_max)],
                         id = 1:nrow(simulation_base)) |>
                  pivot_longer(starts_with("party_"),
                               names_to = "party",
                               values_to = "u_ij") |>
                  mutate(party = as.numeric(gsub("party_", "", party)),
                         vote = as.numeric(gsub("party_", "", vote)),
                         second_vote = as.numeric(gsub("party_", "", second_vote)),
                         real_vote = ifelse(vote == 4, second_vote, vote))

# Display
new_shares = simulation_base |> group_by(real_vote) |>
             summarize("Share %" = 100*n()/nrow(simulation_base))
new_shares    


```
